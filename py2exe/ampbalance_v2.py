#!/usr/bin/env pythonimport sys, os, reimport timeimport threading, threadfrom Bio import SeqIOfrom StringIO import StringIO#import MySQLdbimport stringimport mlpyimport sklearn.preprocessingimport randomimport mathimport csvimport numpy as npimport array as arimport configargparseimport subprocessimport shutilimport globimport h5pyfrom itertools import islicefrom collections import OrderedDictglobal oper#oper="linux"oper="windows"## linux versionif (oper is "linux"):        config_file = os.path.join(os.path.sep, os.path.dirname(os.path.realpath('__file__')), 'amp.config')## linux versionif (oper is "windows"):        config_file = os.path.join(os.path.sep, os.path.dirname(os.path.realpath('__file__')), 'ampW.config')parser = configargparse.ArgParser(description='ampbalance: A program designed to balance amplicons from a specific reference sequence post sequencing on ONT minIONs but prebasecalling. Developed by Matt Loose @mattloose or matt.loose@nottingham.ac.uk for help!',default_config_files=[config_file])parser.add('-fasta', '--reference_fasta_file', type=str, dest='fasta', required=True, default=None, help="The fasta format file for the reference sequence for your organism.")parser.add('-ids', '--reference_id_pos', nargs = '*', dest='ids',required=True, help = 'A list of start and stop positions for each amplicon from the reference genome - should be space separated with fasta_name:start-stop.\n e.g.\n EM_079517:27-1938 EM_078517:1927-3828 EM_078517:3823-5718 EM_078517:5759-7633 EM_078517:7601-10007 EM_078517:9550-10921 EM_078517:10944-12354 EM_078517:12354-14252 EM_078517:14253-15680 EM_078517:15691-17087 EM_078517:16632-18553\n ')parser.add('-w', '--watch-dir', type=str, required=True, default=None, help="The path to the folder containing the downloads directory with fast5 reads to analyse - e.g. C:\data\minion\downloads (for windows).", dest='watchdir')parser.add('-o', '--output-dir', type=str, required=True, default="prefiltered", help="The path to the destination folder for the preprocessed reads" , dest="targetpath")parser.add('-d', '--depth',type=int, required=True, default=None, help = 'The desired coverage depth for each amplicon. Note this is unlikely to be achieved for each amplicon and should probably be an overestimate of the minimum coverage required.', dest='depth')args = parser.parse_args()###########################################################def make_hdf5_object_attr_hash(hdf5object, fields):	att_hash=dict()	for field in fields:		if (field in hdf5object.attrs.keys() ):			#print "filed: ",field (args.ref_fasta is not None), hdf5object.attrs[field]			att_hash[field]=hdf5object.attrs[field]	return att_hash######################################################def process_model_file(model_file):	model_kmers = dict()	with open(model_file, 'rb') as csv_file:		reader = csv.reader(csv_file, delimiter="\t")    		d = list(reader)		#print d		for r in range(1, len(d)):			#print r, d[r]			kmer = d[r][0]			mean = d[r][1]			#print r, kmer, mean			model_kmers[kmer]=mean	return 	model_kmers######################################################def get_amplicons():	for sequence in args.ids:		print sequence		start = int(float(sequence.split(':', 1 )[1].split('-',1)[0]))		stop = int(float(sequence.split(':', 1 )[1].split('-',1)[1]))		print start		print stop		REVERSE_stop = seqlengths['EM_079517']-start		REVERSE_start = seqlengths['EM_079517']-stop		print REVERSE_stop		print REVERSE_start######################################################def get_seq_len(ref_fasta):	seqlens=dict()	for record in SeqIO.parse(ref_fasta, 'fasta'):		seq=record.seq		seqlens[record.id]=len(seq)	return seqlens#######################################################################def runProcess(exe):	p=subprocess.Popen(exe, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)	while(True):		retcode= p.poll()		line=p.stdout.readline()		yield line		if(retcode is not None):			break#######################################################################def squiggle_search2(squiggle,kmerhash2,channel_id,read_id,seqlen):	result=[]	for id in kmerhash2:		for ref in kmerhash2[id]:			#print len(kmerhash2[id][ref]['F'])			queryfile=str(channel_id)+"_"+str(read_id)+"_query.bin"			#We are going to normalise this sequence with the sklearn preprocessing algorithm to see what happens.			queryarray = sklearn.preprocessing.scale(np.array(squiggle),axis=0,with_mean=True,with_std=True,copy=True)			dist, cost, path = mlpy.dtw_subsequence(queryarray,kmerhash2[id][ref]['Fprime'])			result.append((dist,id,"F",path[1][0],ref))			dist, cost, path = mlpy.dtw_subsequence(queryarray,kmerhash2[id][ref]['Rprime'])			result.append((dist,id,"R",path[1][0],ref))	return sorted(result,key=lambda result: result[0])[0][1],sorted(result,key=lambda result: result[0])[0][0],sorted(result,key=lambda result: result[0])[0][2],sorted(result,key=lambda result: result[0])[0][3],sorted(result,key=lambda result: result[0])[0][4]######################################################################def checkhairpin(squiggle,hairpin):	queryarray = sklearn.preprocessing.scale(np.array(hairpin),axis=0,with_mean=True,with_std=True,copy=True)	subjectarray = sklearn.preprocessing.scale(np.array(squiggle),axis=0,with_mean=True,with_std=True,copy=True)	dist,cost,path=mlpy.dtw_subsequence(queryarray,subjectarray)	return (dist,cost,path)#######################################################################def raw_squiggle_search2(squiggle,hashthang):	result=[]	for ref in hashthang:		queryarray = sklearn.preprocessing.scale(np.array(squiggle),axis=0,with_mean=True,with_std=False,copy=True)		dist, cost, path = mlpy.dtw_subsequence(queryarray,hashthang[ref]['Fprime'])		result.append((dist,ref,"F",path[1][0],path[1][-1],path[0][0],path[0][-1]))		dist, cost, path = mlpy.dtw_subsequence(queryarray,hashthang[ref]['Rprime'])		result.append((dist,ref,"R",(len(hashthang[ref]['Rprime'])-path[1][-1]),(len(hashthang[ref]['Rprime'])-path[1][0]),path[0][0],path[0][-1]))	return sorted(result,key=lambda result: result[0])[0][1],sorted(result,key=lambda result: result[0])[0][0],sorted(result,key=lambda result: result[0])[0][2],sorted(result,key=lambda result: result[0])[0][3],sorted(result,key=lambda result: result[0])[0][4],sorted(result,key=lambda result: result[0])[0][5],sorted(result,key=lambda result: result[0])[0][6]######################################################def process_ref_fasta(ref_fasta,model_kmer_means_template,model_kmer_mean_complement):	print "processing the reference fasta."	#ref_kmers=dict()	kmer_len=7	kmer_means=dict()	kmer_means2=dict()	kmer_means3=dict()	for record in SeqIO.parse(ref_fasta, 'fasta'):		counter = 1		kmer_means3[record.id]=dict()		for amplicon in args.ids:			kmer_means3[record.id][counter]=dict()			kmer_means3[record.id][counter]["F"]=list()			kmer_means3[record.id][counter]["R"]=list()			print amplicon			seq = record.seq			#print seq			start = int(float(amplicon.split(':', 1 )[1].split('-',1)[0]))			stop = int(float(amplicon.split(':', 1 )[1].split('-',1)[1]))			newseq=seq[start:stop]			print "Length of newseq:",len(newseq)			shortregion=round(len(newseq)/2)			print shortregion			for x in range(int(shortregion),len(newseq)-kmer_len):				kmer = str(newseq[x:x+kmer_len])				kmer_means3[record.id][counter]["F"].append(float(model_kmer_means_complement[kmer]))			print counter,"F",newseq			newseq2 = revcomp = newseq.reverse_complement()			#for x in range(len(newseq2)+1-kmer_len):			for x in range(int(shortregion),len(newseq2)-kmer_len):				kmer = str(newseq2[x:x+kmer_len])				kmer_means3[record.id][counter]["R"].append(float(model_kmer_means_complement[kmer]))			print counter,"R",newseq2			kmer_means3[record.id][counter]["Fprime"]=sklearn.preprocessing.scale(kmer_means3[record.id][counter]["F"], axis=0, with_mean=True, with_std=True, copy=True)			kmer_means3[record.id][counter]["Rprime"]=sklearn.preprocessing.scale(kmer_means3[record.id][counter]["R"], axis=0, with_mean=True, with_std=True, copy=True)			counter += 1	for record in SeqIO.parse(ref_fasta, 'fasta'):		counter = 1		kmer_means2[record.id]=dict()		for amplicon in args.ids:			kmer_means2[record.id][counter]=dict()			kmer_means2[record.id][counter]["F"]=list()			kmer_means2[record.id][counter]["R"]=list()			print amplicon			seq = record.seq			#print seq			start = int(float(amplicon.split(':', 1 )[1].split('-',1)[0]))			stop = int(float(amplicon.split(':', 1 )[1].split('-',1)[1]))			newseq=seq[start:stop]			print "Length of newseq:",len(newseq)			shortregion=round(len(newseq)/2)			print shortregion			for x in range(int(shortregion)):				kmer = str(newseq[x:x+kmer_len])				kmer_means2[record.id][counter]["F"].append(float(model_kmer_means_template[kmer]))			print counter,"F",newseq			newseq2 = revcomp = newseq.reverse_complement()			#for x in range(len(newseq2)+1-kmer_len):			for x in range(int(shortregion)):				kmer = str(newseq2[x:x+kmer_len])				kmer_means2[record.id][counter]["R"].append(float(model_kmer_means_template[kmer]))			print counter,"R",newseq2			kmer_means2[record.id][counter]["Fprime"]=sklearn.preprocessing.scale(kmer_means2[record.id][counter]["F"], axis=0, with_mean=True, with_std=True, copy=True)			kmer_means2[record.id][counter]["Rprime"]=sklearn.preprocessing.scale(kmer_means2[record.id][counter]["R"], axis=0, with_mean=True, with_std=True, copy=True)			counter += 1	return kmer_means2,kmer_means3######################################################def process_ref_fasta_raw(ref_fasta,model_kmer_means):	print "processing the reference fasta."	kmer_len=7	kmer_means=dict()	for record in SeqIO.parse(ref_fasta, 'fasta'):		kmer_means[record.id]=dict()		kmer_means[record.id]["F"]=list()		kmer_means[record.id]["R"]=list()		kmer_means[record.id]["Fprime"]=list()		kmer_means[record.id]["Rprime"]=list()		print "ID", record.id		print "length", len(record.seq)		print "FORWARD STRAND"		seq = record.seq		for x in range(len(seq)+1-kmer_len):			kmer = str(seq[x:x+kmer_len])			kmer_means[record.id]["F"].append(float(model_kmer_means[kmer]))			#if model_kmer_means[kmer]:				#print x, kmer, model_kmer_means[kmer]		print "REVERSE STRAND"		seq = revcomp = record.seq.reverse_complement()		for x in range(len(seq)+1-kmer_len):			kmer = str(seq[x:x+kmer_len])			kmer_means[record.id]["R"].append(float(model_kmer_means[kmer]))		kmer_means[record.id]["Fprime"]=sklearn.preprocessing.scale(kmer_means[record.id]["F"], axis=0, with_mean=True, with_std=False, copy=True)		kmer_means[record.id]["Rprime"]=sklearn.preprocessing.scale(kmer_means[record.id]["R"], axis=0, with_mean=True, with_std=False, copy=True)	return kmer_means#######################################################################fasta_file = args.fasta#fasta_file = "EM_079517.fasta"model_file_template = "template_a68_2_final_model_501.model"model_file_complement = "complement_a70_final_model_101.model"model_kmer_means_template=process_model_file(model_file_template)model_kmer_means_complement=process_model_file(model_file_complement)kmerhashT = process_ref_fasta_raw(fasta_file,model_kmer_means_template)kmerhashC = process_ref_fasta_raw(fasta_file,model_kmer_means_complement)kmerhash2,kmerhash3 = process_ref_fasta(fasta_file,model_kmer_means_template,model_kmer_means_complement)seqlengths = get_seq_len(fasta_file)get_amplicons()goodcount=0badcount=0truegood=0truebad=0mismatch=0notbasecalled=0reallygood=0reallybad=0reallytruegood=0reallymismatch=0reallynotbasecalled=0###Make a list of starts and stops:ampdict=[]ampstartdict=dict()ampenddict=dict()counter = 0for amplicon in args.ids:	counter+=1	ampstart = int(float(amplicon.split(':', 1 )[1].split('-',1)[0]))	ampstop = int(float(amplicon.split(':', 1 )[1].split('-',1)[1]))	ampstartdict[counter]=ampstart	ampenddict[counter]=ampstop	ampdict.append((counter,ampstart,ampstop))print "******AMP DICTIONARY*******"print type(ampstartdict)print ampstartdict#sys.exit()###A dictionary to store our results inreadprediction=dict()print "Now we are going to try and open the raw reads and do the same as we have done above..."for filename in glob.glob(os.path.join(args.watchdir, '*.fast5')):    print filename    hdf = h5py.File(filename, 'r')    #try:    for read in hdf['Analyses']['EventDetection_000']['Reads']:        events = hdf['Analyses']['EventDetection_000']['Reads'][read]['Events'][()]        event_collection=list()        for event in events:            event_collection.append(event[2])        read_id_fields = ['duration','hairpin_found','hairpin_event_index','read_number','scaling_used','start_mux','start_time',]        #print "!!!!!!READ IS",read        read_info_hash =  make_hdf5_object_attr_hash(hdf['Analyses/EventDetection_000/Reads/'+read],read_id_fields)        #print read_info_hash['hairpin_found']        if read_info_hash['hairpin_found']==1:            print "!!!!!!!!!!!Hairpin Found!!!!!!!!!!!"            print "Template Length:", len(event_collection[0:read_info_hash['hairpin_event_index']])            print "Complement Length:", len(event_collection[read_info_hash['hairpin_event_index']:len(event_collection)])            try:                (seqmatchnameT,distanceT,frT,rsT,reT,qsT,qeT) = raw_squiggle_search2(event_collection[0:read_info_hash['hairpin_event_index']],kmerhashT)            except Exception,err:                print "A time warp failed:", err	#		print (seqmatchnameT,distanceT,frT,rsT,reT,qsT,qeT)			#print squiggle_search2(meansquiggle[0:read_info_hash['hairpin_event_index']],kmerhash)            try:                (seqmatchnameC,distanceC,frC,rsC,reC,qsC,qeC) = raw_squiggle_search2(event_collection[read_info_hash['hairpin_event_index']:len(event_collection)],kmerhashC)            except Exception,err:                print "A time warp failed:", err            #print (seqmatchnameC,distanceC,frC,rsC,reC,qsC,qeC)			### If the forward and reverse reads map appropriately and overlap to the reference we upload template,complement and 2d. But what coordinate do we give for the 2D? Perhaps the overlap region?            if (seqmatchnameC==seqmatchnameT and frT != frC and reC >= rsT and rsC <= reT):                print "Good Candidate"                if (rsT < rsC):                    start = rsT                else:                    start = rsC                if (reT > reC):                    end = reT                else:                    end = reC                for amplicon in args.ids:                    ampstart = int(float(amplicon.split(':', 1 )[1].split('-',1)[0]))                    ampstop = int(float(amplicon.split(':', 1 )[1].split('-',1)[1]))					#print ampstart,ampstop                print start,end                #target = 3.19                amplicon, value = min(ampstartdict.items(), key=lambda (_, v): abs(v - start))                #print min(ampstarttuple, key=lambda y:ampstarttuple[y]-start)                print amplicon, value                key2, value2 = min(ampenddict.items(), key=lambda (_, v): abs(v - end))                #print min(ampstarttuple, key=lambda y:ampstarttuple[y]-start)                print key2, value2                if amplicon == key2:                    if (amplicon not in readprediction):                        readprediction[amplicon]=dict()                    if ("0" not in readprediction[amplicon]):                        readprediction[amplicon]["0"]=dict()                    if (filename not in readprediction[amplicon]["0"]):                        readprediction[amplicon]["0"][filename]=dict()                    readprediction[amplicon]["0"][filename]["name"]=filename                    readprediction[amplicon]["0"][filename]["matchdistance"]=distanceT                else:                    if (amplicon not in readprediction):                        readprediction[amplicon]=dict()                    if ("1" not in readprediction[amplicon]):                        readprediction[amplicon]["1"]=dict()                    if (filename not in readprediction[amplicon]["1"]):                        readprediction[amplicon]["1"][filename]=dict()                    readprediction[amplicon]["1"][filename]["name"]=filename                    readprediction[amplicon]["1"][filename]["matchdistance"]=distanceT            else:                print "We didn't satisfy something here"                print "Template",frT,rsT,reT                print "Complement",frC,rsC,reC        else:            print "!!!!!!!!!!!Hairpin Not Found!!!!!!!!!!!"    #except Exception, err:    #    print "Sorry - couldn't process read ",read    #    print "Any usefull error message is ",err    hdf.close()print "Amplicon Read Counts"for amplicon in readprediction:	numberofreads = 0	try:		if len(readprediction[amplicon]["0"].keys()) > 0:			numberofreads += len(readprediction[amplicon]["0"].keys())	except Exception, err:			print "",	try:		if len(readprediction[amplicon]["1"].keys()) > 0:			numberofreads += len(readprediction[amplicon]["1"].keys())	except Exception, err:			print "",	try:		if len(readprediction[amplicon]["2"].keys()) > 0:			numberofreads += len(readprediction[amplicon]["2"].keys())	except Exception, err:			print "",	try:		if len(readprediction[amplicon]["3"].keys()) > 0:			numberofreads += len(readprediction[amplicon]["3"].keys())	except Exception, err:			print "",	try:		if len(readprediction[amplicon]["4"].keys()) > 0:			numberofreads += len(readprediction[amplicon]["4"].keys())	except Exception, err:			print "",	print ""	print "Amplicon Number:",amplicon,"Reads:",numberofreadsprint ""print "Copying Amplicon Data"for amplicon in readprediction:	print "Amplicon Number",amplicon	counter = 0	try:		if (len(readprediction[amplicon]["0"].keys())>0):			print len(readprediction[amplicon]["0"].keys())			if (counter < args.depth):				ordered0 = OrderedDict(sorted(readprediction[amplicon]["0"].iteritems(), key=lambda x: x[1]['matchdistance']))				#print ordered1				#ordered0 = readprediction[amplicon]["0"].iteritems()				for read in ordered0:					print read, ordered0[read]["matchdistance"]					if not os.path.exists(args.targetpath):						os.makedirs(args.targetpath)					destdir = os.path.join(args.targetpath)					if not os.path.exists(destdir):						os.makedirs(destdir)					try:						filetocheck = os.path.split(read)						#subdir=readlookup[filetocheck[1]]						#sourcefile = os.path.join(filetocheck[0],'downloads',subdir,filetocheck[1])						sourcefile = read						destfile = os.path.join(destdir,filetocheck[1])						#sourcefile = filename						#filename = ids[5]+'.fast5'						#destfile = os.path.join(destdir,filename)						print "sourcefile is:",sourcefile						print "destfile is:",destfile						try:							#os.symlink(sourcefile, destfile)							shutil.copy(sourcefile,destfile)						except Exception, err:							print "File Copy Failed",err					except Exception, err:						print "Weird bug I don't GROK"					counter += 1					if counter >= args.depth:						break				#for read in sorted(readprediction[amplicon]["0"].iteritems(), key=lambda x: x[1]["matchdistance"]):			#	print read, readprediction[amplicon]["0"][read]["matchdistance"]	except Exception, err:		print "No reads of class 0"	try:		if (len(readprediction[amplicon]["1"].keys())>0):			print len(readprediction[amplicon]["1"].keys())			if (counter < args.depth):				ordered1 = OrderedDict(sorted(readprediction[amplicon]["1"].iteritems(), key=lambda x: x[1]['matchdistance']))				#print ordered1				#ordered1 = readprediction[amplicon]["1"].iteritems()				for read in ordered1:					print read, ordered1[read]["matchdistance"]					if not os.path.exists(args.targetpath):						os.makedirs(args.targetpath)					destdir = os.path.join(args.targetpath)					if not os.path.exists(destdir):						os.makedirs(destdir)					try:						filetocheck = os.path.split(read)						#subdir=readlookup[filetocheck[1]]						#sourcefile = os.path.join(filetocheck[0],'downloads',subdir,filetocheck[1])						sourcefile = read						destfile = os.path.join(destdir,filetocheck[1])						#sourcefile = filename						#filename = ids[5]+'.fast5'						#destfile = os.path.join(destdir,filename)						print "sourcefile is:",sourcefile						print "destfile is:",destfile						try:							#os.symlink(sourcefile, destfile)							shutil.copy(sourcefile,destfile)						except Exception, err:							print "File Copy Failed",err					except Exception, err:						print "Weird bug I don't GROK"					counter += 1					if counter >= args.depth:						break				#for read in sorted(readprediction[amplicon]["1"].iteritems(), key=lambda x: x[1]["matchdistance"]):			#	print read, readprediction[amplicon]["1"][read]["matchdistance"]	except Exception, err:		print "No reads of class 1"	try:		if (len(readprediction[amplicon]["2"].keys())>0):			print len(readprediction[amplicon]["2"].keys())			if (counter < args.depth):				ordered2 = OrderedDict(sorted(readprediction[amplicon]["2"].iteritems(), key=lambda x: x[2]['matchdistance']))				#ordered2 = readprediction[amplicon]["2"].iteritems()				#print ordered1				for read in ordered2:					print read, ordered2[read]["matchdistance"]					if not os.path.exists(args.targetpath):						os.makedirs(args.targetpath)					destdir = os.path.join(args.targetpath)					if not os.path.exists(destdir):						os.makedirs(destdir)					try:						filetocheck = os.path.split(read)						#subdir=readlookup[filetocheck[1]]						#sourcefile = os.path.join(filetocheck[0],'downloads',subdir,filetocheck[1])						sourcefile = read						destfile = os.path.join(destdir,filetocheck[1])						#sourcefile = filename						#filename = ids[5]+'.fast5'						#destfile = os.path.join(destdir,filename)						print "sourcefile is:",sourcefile						print "destfile is:",destfile						try:							#os.symlink(sourcefile, destfile)							shutil.copy(sourcefile,destfile)						except Exception, err:							print "File Copy Failed",err					except Exception, err:						print "Weird bug I don't GROK"					counter += 1					if counter >= args.depth:						break	except Exception, err:		print "No reads of class 2"	try:		if (len(readprediction[amplicon]["3"].keys())>0):			print len(readprediction[amplicon]["3"].keys())			if (counter < args.depth):				ordered3 = OrderedDict(sorted(readprediction[amplicon]["3"].iteritems(), key=lambda x: x[3]['matchdistance']))				#ordered3 = readprediction[amplicon]["3"].iteritems()				#print ordered1				for read in ordered3:					print read, ordered3[read]["matchdistance"]					if not os.path.exists(args.targetpath):						os.makedirs(args.targetpath)					destdir = os.path.join(args.targetpath)					if not os.path.exists(destdir):						os.makedirs(destdir)					try:						filetocheck = os.path.split(read)						#subdir=readlookup[filetocheck[1]]						#sourcefile = os.path.join(filetocheck[0],'downloads',subdir,filetocheck[1])						sourcefile = read						destfile = os.path.join(destdir,filetocheck[1])						#sourcefile = filename						#filename = ids[5]+'.fast5'						#destfile = os.path.join(destdir,filename)						print "sourcefile is:",sourcefile						print "destfile is:",destfile						try:							#os.symlink(sourcefile, destfile)							shutil.copy(sourcefile,destfile)						except Exception, err:							print "File Copy Failed",err					except Exception, err:						print "Weird bug I don't GROK"					counter += 1					if counter >= args.depth:						break	except Exception, err:		print "No reads of class 3"	try:		if (len(readprediction[amplicon]["4"].keys())>0):			print len(readprediction[amplicon]["4"].keys())			if (counter < args.depth):				ordered4 = OrderedDict(sorted(readprediction[amplicon]["4"].iteritems(), key=lambda x: x[4]['matchdistance']))				#ordered4 = readprediction[amplicon]["4"].iteritems()				#print ordered1				for read in ordered4:					print read, ordered4[read]["matchdistance"]					if not os.path.exists(args.targetpath):						os.makedirs(args.targetpath)					destdir = os.path.join(args.targetpath)					if not os.path.exists(destdir):						os.makedirs(destdir)					try:						filetocheck = os.path.split(read)						#subdir=readlookup[filetocheck[1]]						#sourcefile = os.path.join(filetocheck[0],'downloads',subdir,filetocheck[1])						sourcefile = read						destfile = os.path.join(destdir,filetocheck[1])						#sourcefile = filename						#filename = ids[5]+'.fast5'						#destfile = os.path.join(destdir,filename)						print "sourcefile is:",sourcefile						print "destfile is:",destfile						try:							#os.symlink(sourcefile, destfile)							shutil.copy(sourcefile,destfile)						except Exception, err:							print "File Copy Failed",err					except Exception, err:						print "Weird bug I don't GROK"					counter += 1					if counter >= args.depth:						break	except Exception, err:		print "No reads of class 4"